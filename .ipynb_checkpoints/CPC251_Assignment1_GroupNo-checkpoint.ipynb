{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39d43a4e",
   "metadata": {},
   "source": [
    "Note: Use this template to develop your project. Do not change the steps. For each step, you may add additional cells if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9b28a8",
   "metadata": {},
   "source": [
    "#### Group Information\n",
    "\n",
    "Group No: \n",
    "\n",
    "- Member 1: \n",
    "- Member 2:\n",
    "- Member 3:\n",
    "- Member 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79b84136",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi=False\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dceb4ff",
   "metadata": {},
   "source": [
    "#### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a83d38c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('classification_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0f56c6",
   "metadata": {},
   "source": [
    "#### Define the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b4024775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    This function calculates the loss function\n",
    "    \"\"\"\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753a2eca",
   "metadata": {},
   "source": [
    "#### Define function to perform prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e165d82-5b8e-47c8-a4ab-86e977c49f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\" \n",
    "    This function calculates the sigmoid function.\n",
    "    \"\"\"\n",
    "    return 1 / (1 + tf.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    \"\"\" \n",
    "    This function calculates the ReLU function.\n",
    "    \"\"\"\n",
    "    return tf.maximum(0, x)\n",
    "\n",
    "def forward(inputs, weights, biases):\n",
    "    \"\"\" \n",
    "    This function calculates the forward pass (predicts the label).\n",
    "    \"\"\"\n",
    "    hidden_output = relu(tf.matmul(inputs, weights[0]) + biases[0])\n",
    "    output = tf.matmul(hidden_output, weights[1]) + biases[1]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bc735b",
   "metadata": {},
   "source": [
    "#### Define function for model training\n",
    "Display the training and validation loss values for each epoch of the training loop. The displayed value must be in 6 decimal places.<br>\n",
    "Hint: <br>\n",
    "Use `tf.GradientTape` to compute the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe17ccc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def train(model, optimizer, x_train, y_train, weights, biases):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(x_train, weights, biases)\n",
    "        loss = tf.reduce_mean(tf.square(predictions - y_train))  # Mean Squared Error loss\n",
    "    \n",
    "    gradients = tape.gradient(loss, weights + biases)\n",
    "    optimizer.apply_gradients(zip(gradients, weights + biases))\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "def fit(model, optimizer, train_data, valid_data, weights, biases, epochs, batch_size, patience):\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    best_valid_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch + 1, epochs))\n",
    "        epoch_train_loss = 0.0\n",
    "        \n",
    "        # Mini-batch training loop\n",
    "        for batch in range(len(train_data[0]) // batch_size):\n",
    "            start = batch * batch_size\n",
    "            end = start + batch_size\n",
    "            x_batch = train_data[0][start:end]\n",
    "            y_batch = train_data[1][start:end]\n",
    "            batch_loss = train(model, optimizer, x_batch, y_batch, weights, biases)\n",
    "            epoch_train_loss += batch_loss.numpy()\n",
    "        \n",
    "        epoch_train_loss /= len(train_data[0]) // batch_size\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        print(\"Epoch Train Loss: {:.6f}\".format(epoch_train_loss))\n",
    "        \n",
    "        # Validation loss\n",
    "        val_predictions = model(valid_data[0], weights, biases)\n",
    "        val_loss = tf.reduce_mean(tf.square(val_predictions - valid_data[1]))\n",
    "        valid_loss = val_loss.numpy()\n",
    "        valid_losses.append(valid_loss)\n",
    "        print(\"Epoch Valid Loss: {:.6f}\".format(valid_loss))\n",
    "        \n",
    "        # Early stopping\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve == patience:\n",
    "                print(\"Early stopping! No improvement in validation loss for {} epochs.\".format(patience))\n",
    "                break\n",
    "    \n",
    "    return train_losses, valid_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f45213",
   "metadata": {},
   "source": [
    "#### Define the tensors to hold the weights and biases (create the model)\n",
    "Hint: <br>\n",
    "Use `tf.Variable` to create the tensors.<br>\n",
    "Put the tensors in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a2e2172b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dimensions of the layers\n",
    "input_dim = 5  # This should be the number of input features\n",
    "hidden_dim = 20  # This can be any number you choose\n",
    "output_dim = 1  # This should be the number of output classes\n",
    "\n",
    "# Initialize the weights and biases with random values\n",
    "weights = [\n",
    "    tf.Variable(tf.random.normal([input_dim, hidden_dim]), name='W1'),\n",
    "    tf.Variable(tf.random.normal([hidden_dim, output_dim]), name='W2')\n",
    "]\n",
    "\n",
    "biases = [\n",
    "    tf.Variable(tf.zeros([hidden_dim]), name='b1'),\n",
    "    tf.Variable(tf.zeros([output_dim]), name='b2')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176badb8",
   "metadata": {},
   "source": [
    "#### Split the dataset\n",
    "The ratio of training and test is 7:1:2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5fa1b9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training set: 700\n",
      "Length of validation set: 100\n",
      "Length of test set: 200\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming dataset is your dataset\n",
    "X = dataset.drop('label', axis=1)\n",
    "y = dataset['label']\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=None)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.125, random_state=None)  # 0.125 x 0.8 = 0.1\n",
    "\n",
    "# Print the lengths of each set\n",
    "print(\"Length of training set:\", len(X_train))\n",
    "print(\"Length of validation set:\", len(X_val))\n",
    "print(\"Length of test set:\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c4d6cf",
   "metadata": {},
   "source": [
    "#### Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f689b7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Initialize a new StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the training data and transform it\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Use the same scaler to transform the validation and test data\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a2e7d6",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6304c496",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train Loss: 13.610269\n",
      "Epoch Valid Loss: 5.435798\n",
      "Epoch 2/200\n",
      "Epoch Train Loss: 3.600286\n",
      "Epoch Valid Loss: 2.455524\n",
      "Epoch 3/200\n",
      "Epoch Train Loss: 1.881054\n",
      "Epoch Valid Loss: 1.462187\n",
      "Epoch 4/200\n",
      "Epoch Train Loss: 1.303354\n",
      "Epoch Valid Loss: 1.085998\n",
      "Epoch 5/200\n",
      "Epoch Train Loss: 0.994420\n",
      "Epoch Valid Loss: 0.872271\n",
      "Epoch 6/200\n",
      "Epoch Train Loss: 0.811069\n",
      "Epoch Valid Loss: 0.742512\n",
      "Epoch 7/200\n",
      "Epoch Train Loss: 0.691315\n",
      "Epoch Valid Loss: 0.664450\n",
      "Epoch 8/200\n",
      "Epoch Train Loss: 0.609126\n",
      "Epoch Valid Loss: 0.611956\n",
      "Epoch 9/200\n",
      "Epoch Train Loss: 0.550741\n",
      "Epoch Valid Loss: 0.573219\n",
      "Epoch 10/200\n",
      "Epoch Train Loss: 0.507067\n",
      "Epoch Valid Loss: 0.542641\n",
      "Epoch 11/200\n",
      "Epoch Train Loss: 0.474141\n",
      "Epoch Valid Loss: 0.516146\n",
      "Epoch 12/200\n",
      "Epoch Train Loss: 0.448739\n",
      "Epoch Valid Loss: 0.493344\n",
      "Epoch 13/200\n",
      "Epoch Train Loss: 0.428321\n",
      "Epoch Valid Loss: 0.473809\n",
      "Epoch 14/200\n",
      "Epoch Train Loss: 0.410885\n",
      "Epoch Valid Loss: 0.457131\n",
      "Epoch 15/200\n",
      "Epoch Train Loss: 0.395902\n",
      "Epoch Valid Loss: 0.442289\n",
      "Epoch 16/200\n",
      "Epoch Train Loss: 0.382919\n",
      "Epoch Valid Loss: 0.428210\n",
      "Epoch 17/200\n",
      "Epoch Train Loss: 0.371816\n",
      "Epoch Valid Loss: 0.415373\n",
      "Epoch 18/200\n",
      "Epoch Train Loss: 0.362251\n",
      "Epoch Valid Loss: 0.404068\n",
      "Epoch 19/200\n",
      "Epoch Train Loss: 0.353917\n",
      "Epoch Valid Loss: 0.393905\n",
      "Epoch 20/200\n",
      "Epoch Train Loss: 0.346646\n",
      "Epoch Valid Loss: 0.384010\n",
      "Epoch 21/200\n",
      "Epoch Train Loss: 0.340283\n",
      "Epoch Valid Loss: 0.375455\n",
      "Epoch 22/200\n",
      "Epoch Train Loss: 0.334640\n",
      "Epoch Valid Loss: 0.367438\n",
      "Epoch 23/200\n",
      "Epoch Train Loss: 0.329611\n",
      "Epoch Valid Loss: 0.360168\n",
      "Epoch 24/200\n",
      "Epoch Train Loss: 0.324985\n",
      "Epoch Valid Loss: 0.353570\n",
      "Epoch 25/200\n",
      "Epoch Train Loss: 0.320691\n",
      "Epoch Valid Loss: 0.347478\n",
      "Epoch 26/200\n",
      "Epoch Train Loss: 0.316792\n",
      "Epoch Valid Loss: 0.341646\n",
      "Epoch 27/200\n",
      "Epoch Train Loss: 0.313028\n",
      "Epoch Valid Loss: 0.336187\n",
      "Epoch 28/200\n",
      "Epoch Train Loss: 0.309610\n",
      "Epoch Valid Loss: 0.331141\n",
      "Epoch 29/200\n",
      "Epoch Train Loss: 0.306425\n",
      "Epoch Valid Loss: 0.326213\n",
      "Epoch 30/200\n",
      "Epoch Train Loss: 0.303430\n",
      "Epoch Valid Loss: 0.321827\n",
      "Epoch 31/200\n",
      "Epoch Train Loss: 0.300419\n",
      "Epoch Valid Loss: 0.317535\n",
      "Epoch 32/200\n",
      "Epoch Train Loss: 0.297349\n",
      "Epoch Valid Loss: 0.313759\n",
      "Epoch 33/200\n",
      "Epoch Train Loss: 0.294393\n",
      "Epoch Valid Loss: 0.310238\n",
      "Epoch 34/200\n",
      "Epoch Train Loss: 0.291720\n",
      "Epoch Valid Loss: 0.306958\n",
      "Epoch 35/200\n",
      "Epoch Train Loss: 0.289351\n",
      "Epoch Valid Loss: 0.303743\n",
      "Epoch 36/200\n",
      "Epoch Train Loss: 0.287174\n",
      "Epoch Valid Loss: 0.300696\n",
      "Epoch 37/200\n",
      "Epoch Train Loss: 0.285176\n",
      "Epoch Valid Loss: 0.297799\n",
      "Epoch 38/200\n",
      "Epoch Train Loss: 0.283313\n",
      "Epoch Valid Loss: 0.295164\n",
      "Epoch 39/200\n",
      "Epoch Train Loss: 0.281595\n",
      "Epoch Valid Loss: 0.292703\n",
      "Epoch 40/200\n",
      "Epoch Train Loss: 0.279935\n",
      "Epoch Valid Loss: 0.290583\n",
      "Epoch 41/200\n",
      "Epoch Train Loss: 0.278443\n",
      "Epoch Valid Loss: 0.288579\n",
      "Epoch 42/200\n",
      "Epoch Train Loss: 0.277128\n",
      "Epoch Valid Loss: 0.286744\n",
      "Epoch 43/200\n",
      "Epoch Train Loss: 0.276018\n",
      "Epoch Valid Loss: 0.285030\n",
      "Epoch 44/200\n",
      "Epoch Train Loss: 0.274973\n",
      "Epoch Valid Loss: 0.283497\n",
      "Epoch 45/200\n",
      "Epoch Train Loss: 0.274114\n",
      "Epoch Valid Loss: 0.282014\n",
      "Epoch 46/200\n",
      "Epoch Train Loss: 0.273299\n",
      "Epoch Valid Loss: 0.280682\n",
      "Epoch 47/200\n",
      "Epoch Train Loss: 0.272492\n",
      "Epoch Valid Loss: 0.279319\n",
      "Epoch 48/200\n",
      "Epoch Train Loss: 0.271698\n",
      "Epoch Valid Loss: 0.278065\n",
      "Epoch 49/200\n",
      "Epoch Train Loss: 0.271002\n",
      "Epoch Valid Loss: 0.276960\n",
      "Epoch 50/200\n",
      "Epoch Train Loss: 0.270332\n",
      "Epoch Valid Loss: 0.275936\n",
      "Epoch 51/200\n",
      "Epoch Train Loss: 0.269696\n",
      "Epoch Valid Loss: 0.274964\n",
      "Epoch 52/200\n",
      "Epoch Train Loss: 0.269079\n",
      "Epoch Valid Loss: 0.274086\n",
      "Epoch 53/200\n",
      "Epoch Train Loss: 0.268518\n",
      "Epoch Valid Loss: 0.273355\n",
      "Epoch 54/200\n",
      "Epoch Train Loss: 0.268026\n",
      "Epoch Valid Loss: 0.272741\n",
      "Epoch 55/200\n",
      "Epoch Train Loss: 0.267546\n",
      "Epoch Valid Loss: 0.272197\n",
      "Epoch 56/200\n",
      "Epoch Train Loss: 0.267101\n",
      "Epoch Valid Loss: 0.271713\n",
      "Epoch 57/200\n",
      "Epoch Train Loss: 0.266651\n",
      "Epoch Valid Loss: 0.271223\n",
      "Epoch 58/200\n",
      "Epoch Train Loss: 0.266257\n",
      "Epoch Valid Loss: 0.270841\n",
      "Epoch 59/200\n",
      "Epoch Train Loss: 0.265841\n",
      "Epoch Valid Loss: 0.270395\n",
      "Epoch 60/200\n",
      "Epoch Train Loss: 0.265472\n",
      "Epoch Valid Loss: 0.270027\n",
      "Epoch 61/200\n",
      "Epoch Train Loss: 0.265130\n",
      "Epoch Valid Loss: 0.269681\n",
      "Epoch 62/200\n",
      "Epoch Train Loss: 0.264804\n",
      "Epoch Valid Loss: 0.269358\n",
      "Epoch 63/200\n",
      "Epoch Train Loss: 0.264506\n",
      "Epoch Valid Loss: 0.269063\n",
      "Epoch 64/200\n",
      "Epoch Train Loss: 0.264185\n",
      "Epoch Valid Loss: 0.268798\n",
      "Epoch 65/200\n",
      "Epoch Train Loss: 0.263910\n",
      "Epoch Valid Loss: 0.268536\n",
      "Epoch 66/200\n",
      "Epoch Train Loss: 0.263642\n",
      "Epoch Valid Loss: 0.268298\n",
      "Epoch 67/200\n",
      "Epoch Train Loss: 0.263398\n",
      "Epoch Valid Loss: 0.268033\n",
      "Epoch 68/200\n",
      "Epoch Train Loss: 0.263166\n",
      "Epoch Valid Loss: 0.267837\n",
      "Epoch 69/200\n",
      "Epoch Train Loss: 0.262922\n",
      "Epoch Valid Loss: 0.267602\n",
      "Epoch 70/200\n",
      "Epoch Train Loss: 0.262684\n",
      "Epoch Valid Loss: 0.267441\n",
      "Epoch 71/200\n",
      "Epoch Train Loss: 0.262478\n",
      "Epoch Valid Loss: 0.267262\n",
      "Epoch 72/200\n",
      "Epoch Train Loss: 0.262253\n",
      "Epoch Valid Loss: 0.267109\n",
      "Epoch 73/200\n",
      "Epoch Train Loss: 0.262044\n",
      "Epoch Valid Loss: 0.266982\n",
      "Epoch 74/200\n",
      "Epoch Train Loss: 0.261855\n",
      "Epoch Valid Loss: 0.266825\n",
      "Epoch 75/200\n",
      "Epoch Train Loss: 0.261663\n",
      "Epoch Valid Loss: 0.266682\n",
      "Epoch 76/200\n",
      "Epoch Train Loss: 0.261452\n",
      "Epoch Valid Loss: 0.266509\n",
      "Epoch 77/200\n",
      "Epoch Train Loss: 0.261242\n",
      "Epoch Valid Loss: 0.266314\n",
      "Epoch 78/200\n",
      "Epoch Train Loss: 0.261075\n",
      "Epoch Valid Loss: 0.266179\n",
      "Epoch 79/200\n",
      "Epoch Train Loss: 0.260920\n",
      "Epoch Valid Loss: 0.266089\n",
      "Epoch 80/200\n",
      "Epoch Train Loss: 0.260760\n",
      "Epoch Valid Loss: 0.265912\n",
      "Epoch 81/200\n",
      "Epoch Train Loss: 0.260591\n",
      "Epoch Valid Loss: 0.265800\n",
      "Epoch 82/200\n",
      "Epoch Train Loss: 0.260414\n",
      "Epoch Valid Loss: 0.265639\n",
      "Epoch 83/200\n",
      "Epoch Train Loss: 0.260267\n",
      "Epoch Valid Loss: 0.265558\n",
      "Epoch 84/200\n",
      "Epoch Train Loss: 0.260120\n",
      "Epoch Valid Loss: 0.265468\n",
      "Epoch 85/200\n",
      "Epoch Train Loss: 0.259992\n",
      "Epoch Valid Loss: 0.265308\n",
      "Epoch 86/200\n",
      "Epoch Train Loss: 0.259841\n",
      "Epoch Valid Loss: 0.265058\n",
      "Epoch 87/200\n",
      "Epoch Train Loss: 0.259685\n",
      "Epoch Valid Loss: 0.264779\n",
      "Epoch 88/200\n",
      "Epoch Train Loss: 0.259560\n",
      "Epoch Valid Loss: 0.264568\n",
      "Epoch 89/200\n",
      "Epoch Train Loss: 0.259435\n",
      "Epoch Valid Loss: 0.264365\n",
      "Epoch 90/200\n",
      "Epoch Train Loss: 0.259361\n",
      "Epoch Valid Loss: 0.264210\n",
      "Epoch 91/200\n",
      "Epoch Train Loss: 0.259244\n",
      "Epoch Valid Loss: 0.264057\n",
      "Epoch 92/200\n",
      "Epoch Train Loss: 0.259132\n",
      "Epoch Valid Loss: 0.263915\n",
      "Epoch 93/200\n",
      "Epoch Train Loss: 0.259038\n",
      "Epoch Valid Loss: 0.263760\n",
      "Epoch 94/200\n",
      "Epoch Train Loss: 0.258932\n",
      "Epoch Valid Loss: 0.263635\n",
      "Epoch 95/200\n",
      "Epoch Train Loss: 0.258850\n",
      "Epoch Valid Loss: 0.263476\n",
      "Epoch 96/200\n",
      "Epoch Train Loss: 0.258739\n",
      "Epoch Valid Loss: 0.263285\n",
      "Epoch 97/200\n",
      "Epoch Train Loss: 0.258627\n",
      "Epoch Valid Loss: 0.262977\n",
      "Epoch 98/200\n",
      "Epoch Train Loss: 0.258541\n",
      "Epoch Valid Loss: 0.262865\n",
      "Epoch 99/200\n",
      "Epoch Train Loss: 0.258462\n",
      "Epoch Valid Loss: 0.262710\n",
      "Epoch 100/200\n",
      "Epoch Train Loss: 0.258409\n",
      "Epoch Valid Loss: 0.262554\n",
      "Epoch 101/200\n",
      "Epoch Train Loss: 0.258324\n",
      "Epoch Valid Loss: 0.262365\n",
      "Epoch 102/200\n",
      "Epoch Train Loss: 0.258285\n",
      "Epoch Valid Loss: 0.262285\n",
      "Epoch 103/200\n",
      "Epoch Train Loss: 0.258200\n",
      "Epoch Valid Loss: 0.262141\n",
      "Epoch 104/200\n",
      "Epoch Train Loss: 0.258143\n",
      "Epoch Valid Loss: 0.261933\n",
      "Epoch 105/200\n",
      "Epoch Train Loss: 0.258080\n",
      "Epoch Valid Loss: 0.261802\n",
      "Epoch 106/200\n",
      "Epoch Train Loss: 0.258034\n",
      "Epoch Valid Loss: 0.261770\n",
      "Epoch 107/200\n",
      "Epoch Train Loss: 0.257971\n",
      "Epoch Valid Loss: 0.261605\n",
      "Epoch 108/200\n",
      "Epoch Train Loss: 0.257916\n",
      "Epoch Valid Loss: 0.261463\n",
      "Epoch 109/200\n",
      "Epoch Train Loss: 0.257891\n",
      "Epoch Valid Loss: 0.261345\n",
      "Epoch 110/200\n",
      "Epoch Train Loss: 0.257852\n",
      "Epoch Valid Loss: 0.261184\n",
      "Epoch 111/200\n",
      "Epoch Train Loss: 0.257805\n",
      "Epoch Valid Loss: 0.261031\n",
      "Epoch 112/200\n",
      "Epoch Train Loss: 0.257760\n",
      "Epoch Valid Loss: 0.260858\n",
      "Epoch 113/200\n",
      "Epoch Train Loss: 0.257723\n",
      "Epoch Valid Loss: 0.260732\n",
      "Epoch 114/200\n",
      "Epoch Train Loss: 0.257699\n",
      "Epoch Valid Loss: 0.260603\n",
      "Epoch 115/200\n",
      "Epoch Train Loss: 0.257650\n",
      "Epoch Valid Loss: 0.260439\n",
      "Epoch 116/200\n",
      "Epoch Train Loss: 0.257608\n",
      "Epoch Valid Loss: 0.260254\n",
      "Epoch 117/200\n",
      "Epoch Train Loss: 0.257579\n",
      "Epoch Valid Loss: 0.260144\n",
      "Epoch 118/200\n",
      "Epoch Train Loss: 0.257566\n",
      "Epoch Valid Loss: 0.260001\n",
      "Epoch 119/200\n",
      "Epoch Train Loss: 0.257539\n",
      "Epoch Valid Loss: 0.259893\n",
      "Epoch 120/200\n",
      "Epoch Train Loss: 0.257524\n",
      "Epoch Valid Loss: 0.259788\n",
      "Epoch 121/200\n",
      "Epoch Train Loss: 0.257498\n",
      "Epoch Valid Loss: 0.259688\n",
      "Epoch 122/200\n",
      "Epoch Train Loss: 0.257481\n",
      "Epoch Valid Loss: 0.259561\n",
      "Epoch 123/200\n",
      "Epoch Train Loss: 0.257467\n",
      "Epoch Valid Loss: 0.259421\n",
      "Epoch 124/200\n",
      "Epoch Train Loss: 0.257455\n",
      "Epoch Valid Loss: 0.259336\n",
      "Epoch 125/200\n",
      "Epoch Train Loss: 0.257435\n",
      "Epoch Valid Loss: 0.259217\n",
      "Epoch 126/200\n",
      "Epoch Train Loss: 0.257431\n",
      "Epoch Valid Loss: 0.259107\n",
      "Epoch 127/200\n",
      "Epoch Train Loss: 0.257392\n",
      "Epoch Valid Loss: 0.259064\n",
      "Epoch 128/200\n",
      "Epoch Train Loss: 0.257413\n",
      "Epoch Valid Loss: 0.259047\n",
      "Epoch 129/200\n",
      "Epoch Train Loss: 0.257457\n",
      "Epoch Valid Loss: 0.258908\n",
      "Epoch 130/200\n",
      "Epoch Train Loss: 0.257437\n",
      "Epoch Valid Loss: 0.258872\n",
      "Epoch 131/200\n",
      "Epoch Train Loss: 0.257450\n",
      "Epoch Valid Loss: 0.258735\n",
      "Epoch 132/200\n",
      "Epoch Train Loss: 0.257316\n",
      "Epoch Valid Loss: 0.258630\n",
      "Epoch 133/200\n",
      "Epoch Train Loss: 0.257246\n",
      "Epoch Valid Loss: 0.258529\n",
      "Epoch 134/200\n",
      "Epoch Train Loss: 0.257212\n",
      "Epoch Valid Loss: 0.258508\n",
      "Epoch 135/200\n",
      "Epoch Train Loss: 0.257204\n",
      "Epoch Valid Loss: 0.258341\n",
      "Epoch 136/200\n",
      "Epoch Train Loss: 0.257158\n",
      "Epoch Valid Loss: 0.258241\n",
      "Epoch 137/200\n",
      "Epoch Train Loss: 0.257128\n",
      "Epoch Valid Loss: 0.258171\n",
      "Epoch 138/200\n",
      "Epoch Train Loss: 0.257090\n",
      "Epoch Valid Loss: 0.258098\n",
      "Epoch 139/200\n",
      "Epoch Train Loss: 0.257044\n",
      "Epoch Valid Loss: 0.258045\n",
      "Epoch 140/200\n",
      "Epoch Train Loss: 0.257037\n",
      "Epoch Valid Loss: 0.257876\n",
      "Epoch 141/200\n",
      "Epoch Train Loss: 0.257021\n",
      "Epoch Valid Loss: 0.257724\n",
      "Epoch 142/200\n",
      "Epoch Train Loss: 0.256943\n",
      "Epoch Valid Loss: 0.257657\n",
      "Epoch 143/200\n",
      "Epoch Train Loss: 0.256908\n",
      "Epoch Valid Loss: 0.257534\n",
      "Epoch 144/200\n",
      "Epoch Train Loss: 0.256897\n",
      "Epoch Valid Loss: 0.257339\n",
      "Epoch 145/200\n",
      "Epoch Train Loss: 0.256854\n",
      "Epoch Valid Loss: 0.257356\n",
      "Epoch 146/200\n",
      "Epoch Train Loss: 0.256860\n",
      "Epoch Valid Loss: 0.257241\n",
      "Epoch 147/200\n",
      "Epoch Train Loss: 0.256859\n",
      "Epoch Valid Loss: 0.257044\n",
      "Epoch 148/200\n",
      "Epoch Train Loss: 0.256811\n",
      "Epoch Valid Loss: 0.256987\n",
      "Epoch 149/200\n",
      "Epoch Train Loss: 0.256834\n",
      "Epoch Valid Loss: 0.256857\n",
      "Epoch 150/200\n",
      "Epoch Train Loss: 0.256806\n",
      "Epoch Valid Loss: 0.256820\n",
      "Epoch 151/200\n",
      "Epoch Train Loss: 0.256809\n",
      "Epoch Valid Loss: 0.256732\n",
      "Epoch 152/200\n",
      "Epoch Train Loss: 0.256785\n",
      "Epoch Valid Loss: 0.256645\n",
      "Epoch 153/200\n",
      "Epoch Train Loss: 0.256779\n",
      "Epoch Valid Loss: 0.256643\n",
      "Epoch 154/200\n",
      "Epoch Train Loss: 0.256767\n",
      "Epoch Valid Loss: 0.256485\n",
      "Epoch 155/200\n",
      "Epoch Train Loss: 0.256756\n",
      "Epoch Valid Loss: 0.256415\n",
      "Epoch 156/200\n",
      "Epoch Train Loss: 0.256752\n",
      "Epoch Valid Loss: 0.256384\n",
      "Epoch 157/200\n",
      "Epoch Train Loss: 0.256740\n",
      "Epoch Valid Loss: 0.256280\n",
      "Epoch 158/200\n",
      "Epoch Train Loss: 0.256762\n",
      "Epoch Valid Loss: 0.256239\n",
      "Epoch 159/200\n",
      "Epoch Train Loss: 0.256730\n",
      "Epoch Valid Loss: 0.256154\n",
      "Epoch 160/200\n",
      "Epoch Train Loss: 0.256720\n",
      "Epoch Valid Loss: 0.256049\n",
      "Epoch 161/200\n",
      "Epoch Train Loss: 0.256722\n",
      "Epoch Valid Loss: 0.256003\n",
      "Epoch 162/200\n",
      "Epoch Train Loss: 0.256719\n",
      "Epoch Valid Loss: 0.255933\n",
      "Epoch 163/200\n",
      "Epoch Train Loss: 0.256714\n",
      "Epoch Valid Loss: 0.255874\n",
      "Epoch 164/200\n",
      "Epoch Train Loss: 0.256718\n",
      "Epoch Valid Loss: 0.255837\n",
      "Epoch 165/200\n",
      "Epoch Train Loss: 0.256700\n",
      "Epoch Valid Loss: 0.255787\n",
      "Epoch 166/200\n",
      "Epoch Train Loss: 0.256686\n",
      "Epoch Valid Loss: 0.255780\n",
      "Epoch 167/200\n",
      "Epoch Train Loss: 0.256692\n",
      "Epoch Valid Loss: 0.255720\n",
      "Epoch 168/200\n",
      "Epoch Train Loss: 0.256710\n",
      "Epoch Valid Loss: 0.255740\n",
      "Epoch 169/200\n",
      "Epoch Train Loss: 0.256709\n",
      "Epoch Valid Loss: 0.255728\n",
      "Epoch 170/200\n",
      "Epoch Train Loss: 0.256677\n",
      "Epoch Valid Loss: 0.255672\n",
      "Epoch 171/200\n",
      "Epoch Train Loss: 0.256695\n",
      "Epoch Valid Loss: 0.255668\n",
      "Epoch 172/200\n",
      "Epoch Train Loss: 0.256702\n",
      "Epoch Valid Loss: 0.255658\n",
      "Epoch 173/200\n",
      "Epoch Train Loss: 0.256687\n",
      "Epoch Valid Loss: 0.255670\n",
      "Epoch 174/200\n",
      "Epoch Train Loss: 0.256691\n",
      "Epoch Valid Loss: 0.255616\n",
      "Epoch 175/200\n",
      "Epoch Train Loss: 0.256701\n",
      "Epoch Valid Loss: 0.255600\n",
      "Epoch 176/200\n",
      "Epoch Train Loss: 0.256699\n",
      "Epoch Valid Loss: 0.255579\n",
      "Epoch 177/200\n",
      "Epoch Train Loss: 0.256699\n",
      "Epoch Valid Loss: 0.255510\n",
      "Epoch 178/200\n",
      "Epoch Train Loss: 0.256712\n",
      "Epoch Valid Loss: 0.255487\n",
      "Epoch 179/200\n",
      "Epoch Train Loss: 0.256713\n",
      "Epoch Valid Loss: 0.255456\n",
      "Epoch 180/200\n",
      "Epoch Train Loss: 0.256707\n",
      "Epoch Valid Loss: 0.255444\n",
      "Epoch 181/200\n",
      "Epoch Train Loss: 0.256725\n",
      "Epoch Valid Loss: 0.255427\n",
      "Epoch 182/200\n",
      "Epoch Train Loss: 0.256713\n",
      "Epoch Valid Loss: 0.255463\n",
      "Epoch 183/200\n",
      "Epoch Train Loss: 0.256702\n",
      "Epoch Valid Loss: 0.255399\n",
      "Epoch 184/200\n",
      "Epoch Train Loss: 0.256692\n",
      "Epoch Valid Loss: 0.255395\n",
      "Epoch 185/200\n",
      "Epoch Train Loss: 0.256703\n",
      "Epoch Valid Loss: 0.255339\n",
      "Epoch 186/200\n",
      "Epoch Train Loss: 0.256712\n",
      "Epoch Valid Loss: 0.255407\n",
      "Epoch 187/200\n",
      "Epoch Train Loss: 0.256698\n",
      "Epoch Valid Loss: 0.255343\n",
      "Epoch 188/200\n",
      "Epoch Train Loss: 0.256679\n",
      "Epoch Valid Loss: 0.255264\n",
      "Epoch 189/200\n",
      "Epoch Train Loss: 0.256694\n",
      "Epoch Valid Loss: 0.255295\n",
      "Epoch 190/200\n",
      "Epoch Train Loss: 0.256686\n",
      "Epoch Valid Loss: 0.255337\n",
      "Epoch 191/200\n",
      "Epoch Train Loss: 0.256670\n",
      "Epoch Valid Loss: 0.255321\n",
      "Epoch 192/200\n",
      "Epoch Train Loss: 0.256681\n",
      "Epoch Valid Loss: 0.255447\n",
      "Epoch 193/200\n",
      "Epoch Train Loss: 0.256727\n",
      "Epoch Valid Loss: 0.255547\n",
      "Early stopping! No improvement in validation loss for 5 epochs.\n"
     ]
    }
   ],
   "source": [
    "# Define your model here\n",
    "model = forward\n",
    "\n",
    "# Define your optimizer\n",
    "optimizer = tf.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# Convert your datasets to TensorFlow tensors\n",
    "X_train_tensor = tf.convert_to_tensor(X_train_scaled, dtype=tf.float32)\n",
    "y_train_tensor = tf.convert_to_tensor(y_train.values, dtype=tf.float32)\n",
    "X_val_tensor = tf.convert_to_tensor(X_val_scaled, dtype=tf.float32)\n",
    "y_val_tensor = tf.convert_to_tensor(y_val.values, dtype=tf.float32)\n",
    "\n",
    "\n",
    "#Change parameter as needed\n",
    "epochs = 200\n",
    "batch_size = 32\n",
    "patience = 5\n",
    "\n",
    "# Train the model\n",
    "train_losses, valid_losses = fit(model, optimizer, (X_train_tensor, y_train_tensor), (X_val_tensor, y_val_tensor), weights, biases, epochs, batch_size, patience)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c41885",
   "metadata": {},
   "source": [
    "#### Display the training loss and validation loss against epoch graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1812730a-1a58-4302-85ff-7a391f018b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training and validation losses\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(valid_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0b4c38",
   "metadata": {},
   "source": [
    "#### Predict the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a84f73b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.256635\n"
     ]
    }
   ],
   "source": [
    "# Convert your test set to TensorFlow tensors\n",
    "X_test_tensor = tf.convert_to_tensor(X_test_scaled, dtype=tf.float32)\n",
    "y_test_tensor = tf.convert_to_tensor(y_test.values, dtype=tf.float32)\n",
    "\n",
    "# Use the model to make predictions on the test set\n",
    "test_predictions = model(X_test_tensor, weights, biases)\n",
    "\n",
    "# Convert the predictions tensor to a NumPy array\n",
    "test_predictions_np = test_predictions.numpy()\n",
    "\n",
    "# Calculate the test loss using the provided loss function\n",
    "test_loss = loss_fn(y_test_tensor, test_predictions)\n",
    "\n",
    "# Display the test loss\n",
    "print(\"Test Loss: {:.6f}\".format(test_loss.numpy()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d715ef",
   "metadata": {},
   "source": [
    "#### Display the confusion matrix and the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c35deeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[61 41]\n",
      " [84 14]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.42      0.60      0.49       102\n",
      "         1.0       0.25      0.14      0.18        98\n",
      "\n",
      "    accuracy                           0.38       200\n",
      "   macro avg       0.34      0.37      0.34       200\n",
      "weighted avg       0.34      0.38      0.34       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Convert predicted probabilities to binary predictions\n",
    "threshold = 0.5\n",
    "predicted_classes = (test_predictions_np >= threshold).astype(int)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test_tensor.numpy(), predicted_classes)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculate classification report\n",
    "class_report = classification_report(y_test_tensor.numpy(), predicted_classes)\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d9e996-6bea-4f17-8cfb-da3202692575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10906ad-4af9-4631-a664-3658ef5b7015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc2e0de-2abf-4b1c-96a9-9fd53e66d61f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
